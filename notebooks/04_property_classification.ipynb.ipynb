{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTEBOOK 4: 04_property_classification.ipynb ###\n",
    "#\n",
    "# GOAL: To load the 'bandung_housing_FINAL.csv' master file\n",
    "#       and create the definitive 'property_type' column.\n",
    "#       This will use the 3-Stage Hybrid Classification logic.\n",
    "#\n",
    "# INPUT: bandung_housing_FINAL.csv\n",
    "# OUTPUT: bandung_housing_CLASSIFIED.csv\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup (tqdm pandas)\n",
    "tqdm.pandas()\n",
    "\n",
    "# Set display options for full exploration\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "print(\"--- 04_property_classification.ipynb ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# ## Step 1: Load the Master Dataset\n",
    "# ---\n",
    "\n",
    "print(\"\\nStep 1: Loading the master 'bandung_housing_FINAL.csv' file...\")\n",
    "\n",
    "# Path Definitions\n",
    "PROJECT_ROOT = Path(r\"..\")\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# --- INPUT FILE (From Notebook 3) ---\n",
    "MASTER_FILE_PATH = PROCESSED_DIR / \"bandung_housing_FINAL.csv\"\n",
    "\n",
    "# --- OUTPUT FILE (Failsafe for Notebook 5) ---\n",
    "CLASSIFIED_FILE_PATH = PROCESSED_DIR / \"bandung_housing_CLASSIFIED.csv\"\n",
    "\n",
    "try:\n",
    "    # Set data types for 'id' and 'zipcode' to avoid warnings\n",
    "    dtypes = {\n",
    "        'id': 'str',\n",
    "        'zipcode': 'str',\n",
    "        'geo_confidence': 'str'\n",
    "    }\n",
    "    \n",
    "    df_master = pd.read_csv(MASTER_FILE_PATH, dtype=dtypes)\n",
    "    print(f\"Successfully loaded {MASTER_FILE_PATH}\")\n",
    "    print(f\"Total listings loaded: {len(df_master):,}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\u274c ERROR: File not found at {MASTER_FILE_PATH}\")\n",
    "    print(\"Please make sure Notebooks 1, 2, and 3 have been run successfully.\")\n",
    "    sys.exit(1) # Stop the script\n",
    "except Exception as e:\n",
    "    print(f\"\u274c ERROR: Could not load file. {e}\")\n",
    "    sys.exit(1) # Stop the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3555d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# ## Step 2: 3-Stage Hybrid Classification (CORRECTED)\n",
    "# ---\n",
    "\n",
    "print(\"\\nStep 2: Starting 3-Stage 'property_type' classification...\")\n",
    "\n",
    "# ================================================================\n",
    "# STAGE 1 & 2 FUNCTION: \"Smart\" JSON parsing with \"Dumb\" Fallback\n",
    "# ================================================================\n",
    "\n",
    "def get_initial_type_CORRECTED(row):\n",
    "    \"\"\"\n",
    "    Tries to get 'Tipe Properti' from 'specs' JSON (Stage 1).\n",
    "    If it fails, falls back to a SAFER keyword search (Stage 2).\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- STAGE 1: \"Smart\" JSON Parsing ---\n",
    "    try:\n",
    "        spec_data = json.loads(row['specs'])\n",
    "        if 'Tipe Properti' in spec_data:\n",
    "            tipe = spec_data['Tipe Properti'].lower()\n",
    "            if 'rumah' in tipe: return \"Rumah\"\n",
    "            if 'tanah' in tipe: return \"Tanah\"\n",
    "            if 'apartemen' in tipe: return \"Apartemen\"\n",
    "            if 'ruko' in tipe: return \"Ruko\"\n",
    "            if 'villa' in tipe: return \"Villa\"\n",
    "            if any(k in tipe for k in ['kantor', 'gudang']): return \"Ruko\"\n",
    "    except:\n",
    "        pass # Pass to Stage 2\n",
    "\n",
    "    # --- STAGE 2: \"Dumb\" Keyword Fallback (CORRECTED) ---\n",
    "    search_string = \"\"\n",
    "    for col in ['id', 'description', 'master_address', 'specs']:\n",
    "        if col in row.index and isinstance(row[col], str):\n",
    "            search_string += \" \" + row[col].lower()\n",
    "    \n",
    "    # --- THIS IS THE FIX ---\n",
    "    # We check for \"Tanah\" using *specific phrases* first,\n",
    "    # not the general (and poisonous) word \"tanah\".\n",
    "    if any(s in search_string for s in ['jual kavling', 'rumah hitung tanah', 'dijual tanah', 'tanah dijual']):\n",
    "        return \"Tanah\"\n",
    "    # --- END FIX ---\n",
    "    \n",
    "    # Priority List (The rest is the same)\n",
    "    if 'kavling' in search_string: # 'kavling' is specific enough to keep\n",
    "        return \"Tanah\"\n",
    "    if any(s in search_string for s in ['apartemen', 'apartment', 'apartement']):\n",
    "        return \"Apartemen\"\n",
    "    if any(s in search_string for s in ['ruko', 'rukan', 'kantor', 'office', 'gudang', 'warehouse']):\n",
    "        return \"Ruko\"\n",
    "    if 'villa' in search_string:\n",
    "        return \"Villa\"\n",
    "    if any(s in search_string for s in ['rumah', 'house', 'hunian', 'cluster', 'residence']):\n",
    "        return \"Rumah\"\n",
    "    \n",
    "    return \"Lainnya\"\n",
    "\n",
    "# --- Apply Stage 1 and 2 ---\n",
    "print(\"Running Stage 1 (JSON) and Stage 2 (Keyword) classification...\")\n",
    "print(\"This may take a minute...\")\n",
    "df_master['property_type'] = df_master.progress_apply(get_initial_type_CORRECTED, axis=1)\n",
    "print(\"Stage 1 & 2 complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# STAGE 3: \"Symptom\" Polish (The Final Fix)\n",
    "# ================================================================\n",
    "print(\"\\nRunning Stage 3 ('Symptom') polishing...\")\n",
    "\n",
    "# Symptom 1: No building size = 'Tanah'\n",
    "symptom_1_count = len(df_master[\n",
    "    (df_master['property_type'] == 'Rumah') &\n",
    "    (df_master['building_size_sqm'].isnull())\n",
    "])\n",
    "df_master.loc[\n",
    "    (df_master['property_type'] == 'Rumah') & \n",
    "    (df_master['building_size_sqm'].isnull()), \n",
    "    'property_type'\n",
    "] = 'Tanah'\n",
    "print(f\" - Stage 3: Re-classified {symptom_1_count:,} 'Rumah' listings with null 'building_size' as 'Tanah'.\")\n",
    "\n",
    "# Symptom 2: No bedrooms = 'Ruko' / 'Kantor'\n",
    "symptom_2_count = len(df_master[\n",
    "    (df_master['property_type'] == 'Rumah') &\n",
    "    (df_master['bedrooms'].isnull())\n",
    "])\n",
    "df_master.loc[\n",
    "    (df_master['property_type'] == 'Rumah') & \n",
    "    (df_master['bedrooms'].isnull()), \n",
    "    'property_type'\n",
    "] = 'Ruko' # Assume 'Ruko' (Commercial)\n",
    "print(f\" - Stage 3: Re-classified {symptom_2_count:,} 'Rumah' listings with null 'bedrooms' as 'Ruko'.\")\n",
    "\n",
    "# Symptom 3: No bathrooms = 'Tanah'\n",
    "symptom_3_count = len(df_master[\n",
    "    (df_master['property_type'] == 'Rumah') &\n",
    "    (df_master['bathrooms'].isnull())\n",
    "])\n",
    "df_master.loc[\n",
    "    (df_master['property_type'] == 'Rumah') & \n",
    "    (df_master['bathrooms'].isnull()), \n",
    "    'property_type'\n",
    "] = 'Tanah' # Assume 'Tanah'\n",
    "print(f\" - Stage 3: Re-classified {symptom_3_count:,} 'Rumah' listings with null 'bathrooms' as 'Tanah'.\")\n",
    "\n",
    "print(\"\\n3-Stage Classification complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# ## Step 3: Exploration (CRITICAL CHECK)\n",
    "# ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Step 3: Final Classification Results\")\n",
    "print(\"=\"*40)\n",
    "print(\"This is the final breakdown of all property types in the dataset:\")\n",
    "\n",
    "# This is our critical check\n",
    "print(df_master['property_type'].value_counts())\n",
    "\n",
    "\n",
    "# ---\n",
    "# ## Step 4: Save Classified Failsafe File\n",
    "# ---\n",
    "\n",
    "print(\"\\nStep 4: Saving new failsafe file...\")\n",
    "try:\n",
    "    # We save the file with the new 'property_type' column\n",
    "    df_master.to_csv(CLASSIFIED_FILE_PATH, index=False)\n",
    "    print(f\"\\n\u2705\u2705\u2705 04_property_classification.ipynb COMPLETE! \u2705\u2705\u2705\")\n",
    "    print(f\"New failsafe file saved to:\")\n",
    "    print(CLASSIFIED_FILE_PATH)\n",
    "    print(f\"Total listings saved: {len(df_master):,}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\u274c ERROR: Could not save the file. {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bandung-housing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}