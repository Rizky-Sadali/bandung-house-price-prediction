{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf206ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTEBOOK 5: 05_outlier_removal.ipynb ###\n",
    "#\n",
    "# GOAL: To filter the classified dataset for 'Rumah' listings\n",
    "#       and then systematically remove geographic, logical,\n",
    "#       and statistical outliers.\n",
    "#\n",
    "# INPUT: bandung_housing_CLASSIFIED.csv\n",
    "# OUTPUT: bandung_housing_MODEL_READY.csv\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Set display options for full exploration\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "print(\"--- 05_outlier_removal.ipynb ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# ## Step 1: Load and Filter for 'Rumah'\n",
    "# ---\n",
    "\n",
    "print(\"Step 1: Loading 'bandung_housing_CLASSIFIED.csv'...\")\n",
    "\n",
    "# Path Definitions\n",
    "PROJECT_ROOT = Path(r\"..\")\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# --- INPUT FILE (From Notebook 4) ---\n",
    "CLASSIFIED_FILE_PATH = PROCESSED_DIR / \"bandung_housing_CLASSIFIED.csv\"\n",
    "\n",
    "# --- OUTPUT FILE (The final product) ---\n",
    "MODEL_READY_PATH = PROCESSED_DIR / \"bandung_housing_MODEL_READY.csv\"\n",
    "\n",
    "try:\n",
    "    # Set data types for 'id' and 'zipcode' to avoid warnings\n",
    "    dtypes = {\n",
    "        'id': 'str',\n",
    "        'zipcode': 'str',\n",
    "        'geo_confidence': 'str'\n",
    "    }\n",
    "    \n",
    "    df_classified = pd.read_csv(CLASSIFIED_FILE_PATH, dtype=dtypes)\n",
    "    print(f\"Successfully loaded {len(df_classified):,} total listings.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\u274c ERROR: File not found at {CLASSIFIED_FILE_PATH}\")\n",
    "    print(\"Please make sure Notebook 4 ran successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c ERROR: Could not load file. {e}\")\n",
    "\n",
    "\n",
    "# --- Filter for 'Rumah' ---\n",
    "print(\"Filtering for 'property_type' == 'Rumah'...\")\n",
    "\n",
    "df_platform_a = df_classified[df_classified['property_type'] == 'Rumah'].copy()\n",
    "\n",
    "print(f\"Created 'df_platform_a' with {len(df_platform_a):,} listings.\")\n",
    "print(\"--- Step 1 Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platform_a.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3b40c",
   "metadata": {},
   "source": [
    "132 listings (8073 - 7941) are missing their latitude and longitude. They represent a very small fraction of our 'Rumah' data: (132 / 8073) * 100 = 1.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Exploration (Find Missing Coordinates)\n",
    "# ---\n",
    "\n",
    "print(\"Inspecting listings with missing coordinates...\")\n",
    "\n",
    "# Filter for rows where latitude is null\n",
    "missing_coords_df = df_platform_a[df_platform_a['latitude'].isnull()]\n",
    "\n",
    "print(f\"\\nFound {len(missing_coords_df)} listings with missing coordinates.\")\n",
    "\n",
    "# Display key columns of these listings to understand what they are\n",
    "print(\"\\nSample of listings with missing coordinates:\")\n",
    "print(missing_coords_df[[\n",
    "    'id', \n",
    "    'source', \n",
    "    'price', \n",
    "    'master_address', \n",
    "    'bedrooms', \n",
    "    'bathrooms'\n",
    "]].head(10))\n",
    "\n",
    "# You can also check if they were missing a master_address\n",
    "print(f\"\\nOf these, {missing_coords_df['master_address'].isnull().sum()} listings were ALSO missing a 'master_address'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe06f80",
   "metadata": {},
   "source": [
    "these are likely the first 100 in Platform A listings, which didn't have an address or lat/long, even in the initial scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d70c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# ## Step 2: Hapus Listings Tanpa Koordinat\n",
    "# ---\n",
    "\n",
    "print(\"Memulai Step 2: Menghapus listings tanpa data geospasial...\")\n",
    "\n",
    "rows_before = len(df_platform_a)\n",
    "print(f\"Listings 'Rumah' (sebelum): {rows_before:,}\")\n",
    "\n",
    "# Solusi: Timpa df_platform_a dengan versi baru yang telah di-drop\n",
    "# Kita men-drop baris di mana 'latitude' adalah NaT/NaN\n",
    "df_platform_a = df_platform_a.dropna(subset=['latitude'])\n",
    "\n",
    "rows_after = len(df_platform_a)\n",
    "print(f\"Listings 'Rumah' (setelah): {rows_after:,}\")\n",
    "print(f\"Total {rows_before - rows_after} listings 'hantu' telah dihapus.\")\n",
    "\n",
    "print(\"\\n--- Step 2 Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platform_a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platform_a.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef76b52",
   "metadata": {},
   "source": [
    "**Geographic Impossibilities**  \n",
    "**The Problem:**  \n",
    "- Latitude (max: 0.29) and longitude (max: 115.19) are incorrect.  \n",
    "- Bandung\u2019s coordinates are roughly (-6.9, 107.6).  \n",
    "- A longitude of 115 is in Bali, and a latitude of 0.29 is on the equator.  \n",
    "- These are *bad geocodes*.  \n",
    "\n",
    "**Diagnosis:**  \n",
    "- The dataset (`df_platform_a`) contains listings that are not located in Bandung.  \n",
    "\n",
    "---\n",
    "\n",
    "**Logical Impossibilities (Typos)**  \n",
    "**The Problem:**  \n",
    "- `land_size_sqm` (min: 1.00)  \n",
    "- `building_size_sqm` (min: 1.00)  \n",
    "- `price` (min: 2,490,000.00)  \n",
    "\n",
    "**Diagnosis:**  \n",
    "- A 1 sqm house or a 2.4M IDR house is unrealistic.  \n",
    "- These values are typos or bad data entries that will skew the model.  \n",
    "\n",
    "---\n",
    "\n",
    "**Mis-classified Properties**  \n",
    "**The Problem:**  \n",
    "- `bedrooms` (max: 132.00)  \n",
    "- `bathrooms` (max: 142.00)  \n",
    "- `price` (max: 950,000,000,000.00)  \n",
    "\n",
    "**Diagnosis:**  \n",
    "- These are not typical houses (*Rumah*).  \n",
    "- They are likely hotels or large *Kos-kosan* (boarding houses) that the 3-stage classification logic failed to filter.  \n",
    "- The extreme price values also suggest mis-classified properties.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaee4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Bandung's reasonable geographic boundaries\n",
    "MIN_LATITUDE = -7.3\n",
    "MAX_LATITUDE = -6.5\n",
    "MIN_LONGITUDE = 107.0\n",
    "MAX_LONGITUDE = 107.9\n",
    "\n",
    "print(f\"Batas 'Bandung' (Biru) yang digunakan:\")\n",
    "print(f\"  Latitude: {MIN_LATITUDE} sampai {MAX_LATITUDE}\")\n",
    "print(f\"  Longitude: {MIN_LONGITUDE} sampai {MAX_LONGITUDE}\")\n",
    "\n",
    "def classify_location(row):\n",
    "    \"\"\"\n",
    "    Classifies a row as 'Bandung' or 'Outlier' based on its coordinates.\n",
    "    \"\"\"\n",
    "    is_lat_ok = (row['latitude'] >= MIN_LATITUDE) and (row['latitude'] <= MAX_LATITUDE)\n",
    "    is_lon_ok = (row['longitude'] >= MIN_LONGITUDE) and (row['longitude'] <= MAX_LONGITUDE)\n",
    "    \n",
    "    if is_lat_ok and is_lon_ok:\n",
    "        return 'Bandung'\n",
    "    else:\n",
    "        return 'Outlier'\n",
    "\n",
    "# 1. Create the new column for coloring\n",
    "df_platform_a['location_type'] = df_platform_a.apply(classify_location, axis=1)\n",
    "\n",
    "# 2. Check the counts\n",
    "print(\"\\n\" + df_platform_a['location_type'].value_counts().to_string())\n",
    "\n",
    "# 3. Create the plot\n",
    "print(\"Generating plot...\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Use seaborn.scatterplot with the 'hue' parameter\n",
    "# 'hue' tells seaborn to color points based on the 'location_type' column\n",
    "# 'palette' maps our categories to the specific colors you wanted\n",
    "ax = sns.scatterplot(\n",
    "    data=df_platform_a,\n",
    "    x='longitude', \n",
    "    y='latitude',\n",
    "    hue='location_type',         # <-- This colors the dots\n",
    "    palette={'Bandung': 'blue', 'Outlier': 'red'}, # <-- Your color choices\n",
    "    alpha=0.6,                   # A bit of transparency\n",
    "    s=20                         # Point size\n",
    ")\n",
    "\n",
    "ax.set_title('Geographic Diagnosis Plot (Color-Coded): Bandung vs. Outliers', fontsize=16)\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.grid(True)\n",
    "plt.legend(title='Lokasi') # Add a legend\n",
    "plt.show()\n",
    "\n",
    "# 4. Clean up the temporary column (optional, but good practice)\n",
    "# df_platform_a = df_platform_a.drop(columns=['location_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Remove Geographic Outliers \n",
    "# ---\n",
    "\n",
    "rows_before = len(df_platform_a)\n",
    "print(f\"Listings 'Rumah' (sebelum filter): {rows_before:,}\")\n",
    "\n",
    "# 1. Find the indices of the rows we want to drop\n",
    "outlier_indices = df_platform_a[df_platform_a['location_type'] != 'Bandung'].index\n",
    "print(f\"Menemukan {len(outlier_indices)} listings 'Outlier' untuk dihapus.\")\n",
    "\n",
    "# 2. Drop those rows from df_platform_a *in place*\n",
    "df_platform_a.drop(outlier_indices, inplace=True)\n",
    "\n",
    "# 3. Drop the temporary column *in place*\n",
    "df_platform_a.drop(columns=['location_type'], inplace=True)\n",
    "\n",
    "rows_after = len(df_platform_a)\n",
    "print(f\"Listings 'Rumah' (setelah filter): {rows_after:,}\")\n",
    "print(f\"Total {rows_before - rows_after} listings 'Outlier' telah dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platform_a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Diagnose Bedroom Outliers \n",
    "# ---\n",
    "\n",
    "# --- 1. Define Thresholds ---\n",
    "# a \"normal\" house has 1-14 bedrooms.\n",
    "MIN_BEDROOMS_NORMAL = 1\n",
    "MAX_BEDROOMS_NORMAL = 15 # We'll say 15 or more is an outlier\n",
    "\n",
    "# --- 2. Create the Classification Column ---\n",
    "def classify_bedrooms(bedrooms):\n",
    "    if bedrooms < MIN_BEDROOMS_NORMAL:\n",
    "        return 'Outlier (Low)'\n",
    "    if bedrooms >= MAX_BEDROOMS_NORMAL:\n",
    "        return 'Outlier (High)'\n",
    "    return 'Normal'\n",
    "\n",
    "# Apply the function to create the new 'hue' column\n",
    "df_platform_a['bedroom_type'] = df_platform_a['bedrooms'].apply(classify_bedrooms)\n",
    "\n",
    "print(f\"\\nClassification counts:\\n{df_platform_a['bedroom_type'].value_counts().to_string()}\")\n",
    "\n",
    "# --- 3. Create the Color-Coded Plot ---\n",
    "print(\"Generating plot...\")\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Create a countplot, using 'bedroom_type' to color the bars\n",
    "ax = sns.countplot(\n",
    "    data=df_platform_a,\n",
    "    x='bedrooms',\n",
    "    hue='bedroom_type',\n",
    "    # Use your requested colors\n",
    "    palette={'Normal': 'lightgreen', 'Outlier (High)': 'orange', 'Outlier (Low)': 'gray'},\n",
    "    dodge=False # This makes the bars stack/overlap, not dodge\n",
    ")\n",
    "\n",
    "# --- This is the key to making the plot readable ---\n",
    "# We limit the x-axis to see the main distribution\n",
    "ax.set_xlim(-0.5, 20.5) \n",
    "ax.set_xticks(range(0, 21)) # Set ticks for every bedroom 0-20\n",
    "\n",
    "ax.set_title('Diagnosis: Bedroom Count Outliers (0-20 Range)', fontsize=16)\n",
    "ax.set_xlabel('Number of Bedrooms', fontsize=12)\n",
    "ax.set_ylabel('Count of Listings', fontsize=12)\n",
    "plt.legend(title='Category')\n",
    "plt.show()\n",
    "\n",
    "# --- 4. Show the \"Outlier (High)\" Table ---\n",
    "# The plot shows the 'Normal' range. \n",
    "# The table shows the 'Outlier (High)' listings (the ones we need to remove).\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Inspecting the 'Outlier (High)' listings (>= {MAX_BEDROOMS_NORMAL} bedrooms):\")\n",
    "\n",
    "outlier_df = df_platform_a[df_platform_a['bedroom_type'] == 'Outlier (High)']\n",
    "print(outlier_df.sort_values(by='bedrooms', ascending=False)[\n",
    "    ['id', 'master_address', 'price', 'bedrooms', 'bathrooms', 'building_size_sqm']\n",
    "])\n",
    "\n",
    "# Clean up the temporary column\n",
    "df_platform_a = df_platform_a.drop(columns=['bedroom_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdab3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Filter for the \"Outlier (Low)\" listings ---\n",
    "MIN_BEDROOMS_NORMAL = 1\n",
    "MAX_BEDROOMS_NORMAL = 15 \n",
    "\n",
    "def classify_bedrooms(bedrooms):\n",
    "    if bedrooms < MIN_BEDROOMS_NORMAL:\n",
    "        return 'Outlier (Low)'\n",
    "    if bedrooms >= MAX_BEDROOMS_NORMAL:\n",
    "        return 'Outlier (High)'\n",
    "    return 'Normal'\n",
    "\n",
    "df_platform_a['bedroom_type'] = df_platform_a['bedrooms'].apply(classify_bedrooms)\n",
    "\n",
    "# --- 2. Filter for the \"Outlier (Low)\" listings ---\n",
    "low_outliers_df = df_platform_a[df_platform_a['bedroom_type'] == 'Outlier (Low)'].copy()\n",
    "\n",
    "# --- 4. Clean up the temporary column ---\n",
    "df_platform_a = df_platform_a.drop(columns=['bedroom_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_outliers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93a2ab",
   "metadata": {},
   "source": [
    "## List of Anomalies \n",
    "\n",
    "**Persistent Geographic Issues**  \n",
    "Our \"Bandung\" filter is technically a coordinate filter. As you can see, it still includes areas that are not administratively part of Bandung City. \n",
    "Examples:  \n",
    "- Listing #228: Padalarang District, West Bandung Regency  \n",
    "- Listing #809: Sariwangi, Parongpong, West Bandung Regency  \n",
    "- Listing #4194: Cimahi, Cimahi Tengah, Cimahi City  \n",
    "\n",
    "---\n",
    "\n",
    "**Clear Misclassifications (Hotels & Land)**  \n",
    "`bedrooms = 0` should indicate *Land* or *Commercial Property*, but these listings were still classified as *Houses*.  \n",
    "\n",
    "Examples:  \n",
    "- Listing #5670: id = dijual-hotel-di-bandung... description starts with \"Dijual ho...\" \u2192 clearly a Hotel  \n",
    "- Listing #7201: id = hotel-bandung... \u2192 clearly a Hotel  \n",
    "- Listing #4631: id = tanah-mainroad-setiabudi... description starts with \"Tanah Mainroad...\" \u2192 clearly Land  \n",
    "\n",
    "---\n",
    "\n",
    "**Commercial Properties (Shophouses/Business Use)**  \n",
    "Many listings (also with 0 bedrooms) have descriptions that strongly suggest they are commercial properties, not residential houses.  \n",
    "\n",
    "Examples:  \n",
    "- Listing #1194: \"House Can Be Used For Cafe Business...\"  \n",
    "- Listing #3578: \"Residential House With Business Space...\"  \n",
    "- Listing #803: \"House On Mainroad...\" (usually commercial)  \n",
    "\n",
    "---\n",
    "\n",
    "**\"0 Bedrooms, 0 Bathrooms\" Issue**  \n",
    "There are 37 listings with both `bedrooms = 0` and `bathrooms = 0`.  \n",
    "\n",
    "Examples: #689, #809, #1062, #1194, #1335, #3019, #4111, #4631, #4798, #5670, #5757, #5888, #5951, #6290, #6422, #6748, #6982, #6992, #7201.  \n",
    "\n",
    "Note: Listings with 0 bedrooms **and** 0 bathrooms are almost certainly not residential houses.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Remove Persistent Geographic Outliers (Shapefile Solution)\n",
    "# ---\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# --- 1. Define Shapefile Path ---\n",
    "# This is the path from your \"last file.docx\" (IPYNB FILE # 19)\n",
    "shapefile_path = r\"..\\data\\raw\\idn_admbnda_adm4_ID3_bps_20200401.shp\"\n",
    "print(f\"Menggunakan shapefile dari: {shapefile_path}\")\n",
    "\n",
    "# --- 2. Load the Shapefile ---\n",
    "try:\n",
    "    gdf_adm = gpd.read_file(shapefile_path)\n",
    "    print(f\"Shapefile berhasil dimuat, berisi {len(gdf_adm)} total area administrasi.\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c ERROR: Tidak dapat memuat shapefile. Periksa path Anda.\")\n",
    "    print(f\"Error: {e}\")\n",
    "    # Stop execution if the file can't be loaded\n",
    "    raise e\n",
    "\n",
    "# --- 3. Convert 'df_platform_a' to a GeoDataFrame ---\n",
    "print(\"Mengubah 'df_platform_a' (listings) menjadi GeoDataFrame...\")\n",
    "# Create 'geometry' from longitude and latitude\n",
    "gdf_listings = gpd.GeoDataFrame(\n",
    "    df_platform_a, \n",
    "    geometry=gpd.points_from_xy(df_platform_a.longitude, df_platform_a.latitude)\n",
    ")\n",
    "# Set the coordinate reference system (CRS) to standard WGS84 (lat/lon)\n",
    "gdf_listings.set_crs(\"EPSG:4326\", inplace=True) \n",
    "print(f\"Total listings 'Rumah' sebelum spatial join: {len(gdf_listings):,}\")\n",
    "\n",
    "# --- 4. Align Coordinate Systems (CRS) ---\n",
    "print(\"Menyamakan Coordinate Systems (CRS)...\")\n",
    "# Ensure both GeoDataFrames use the same CRS before joining\n",
    "if gdf_listings.crs != gdf_adm.crs:\n",
    "    gdf_listings = gdf_listings.to_crs(gdf_adm.crs)\n",
    "print(\"CRS aligned.\")\n",
    "\n",
    "# --- 5. Perform the Spatial Join (The Filter) ---\n",
    "print(\"Melakukan spatial join (filter) untuk memetakan listings ke area...\")\n",
    "# 'how=\"left\"' keeps all listings, 'predicate=\"within\"' checks which polygon they fall into\n",
    "# This adds columns from gdf_adm (like 'ADM2_EN') to our listings\n",
    "listings_with_adm = gpd.sjoin(gdf_listings, gdf_adm, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# --- 6. Filter to 'Kota Bandung' ---\n",
    "admin_city_column = 'ADM2_EN' # Based on your file\n",
    "city_name = 'Kota Bandung'\n",
    "\n",
    "print(f\"Filtering listings yang berada di dalam '{city_name}'...\")\n",
    "df_kota_bandung = listings_with_adm[\n",
    "    listings_with_adm[admin_city_column] == city_name\n",
    "].copy()\n",
    "\n",
    "print(f\"Ditemukan {len(df_kota_bandung):,} listings di dalam '{city_name}'.\")\n",
    "\n",
    "# --- 7. Clean up and Finalize ---\n",
    "# We update df_platform_a to be this new, filtered DataFrame.\n",
    "# We also drop the extra 'geometry' and 'index_right' columns.\n",
    "columns_to_drop = ['index_right', 'geometry']\n",
    "df_platform_a = df_kota_bandung.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Keep only the original columns + the new sub-district column\n",
    "original_cols = list(df_platform_a.columns)\n",
    "# Remove any new admin columns we don't want, except 'ADM4_EN'\n",
    "admin_cols_to_keep = ['ADM4_EN'] # This is the sub-district name\n",
    "all_cols_to_keep = [col for col in original_cols if col in df_platform_a.columns] + admin_cols_to_keep\n",
    "# Ensure no duplicates\n",
    "final_cols = []\n",
    "for col in all_cols_to_keep:\n",
    "    if col not in final_cols and col in df_platform_a.columns:\n",
    "        final_cols.append(col)\n",
    "\n",
    "df_platform_a = df_platform_a[final_cols]\n",
    "\n",
    "print(f\"\\nTotal listings 'Rumah' SETELAH shapefile filter: {len(df_platform_a):,}\")\n",
    "print(\"--- Step Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platform_a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae384ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Membersihkan Kolom & Mendiagnosis Ulang Outlier Rendah\n",
    "# ---\n",
    "\n",
    "columns_to_drop = [\n",
    "    'date', \n",
    "    'validOn', \n",
    "    'validTo', \n",
    "    'Shape_Leng', \n",
    "    'Shape_Area'\n",
    "]\n",
    "\n",
    "# Kita juga akan memeriksa kolom lain yang mungkin ditambahkan oleh join\n",
    "# (ADM1_EN, ADM2_EN, ADM3_EN, dll) kecuali ADM4_EN\n",
    "# Cek kolom yang ada sebelum mencoba membuangnya\n",
    "existing_cols_to_drop = [col for col in columns_to_drop if col in df_platform_a.columns]\n",
    "if 'ADM2_EN' in df_platform_a.columns:\n",
    "    existing_cols_to_drop.append('ADM2_EN') # Kita sudah tahu ini 'Kota Bandung'\n",
    "if 'ADM3_EN' in df_platform_a.columns:\n",
    "     existing_cols_to_drop.append('ADM3_EN')\n",
    "\n",
    "print(f\"Kolom yang akan dibuang: {existing_cols_to_drop}\")\n",
    "\n",
    "df_platform_a = df_platform_a.drop(columns=existing_cols_to_drop)\n",
    "\n",
    "print(\"Pembersihan kolom selesai.\")\n",
    "print(\"Kolom 'ADM4_EN' (Kecamatan) dipertahankan untuk analisis fitur.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90845c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan 'low_outliers_df' Saat Ini ---\n",
    "print(\"\\nMemulai Tugas 2: Mengisolasi outlier kamar tidur rendah (dari dalam Kota Bandung)...\")\n",
    "\n",
    "# Filter 'df_platform_a' yang baru (6.009 listing) untuk menemukan\n",
    "# listing dengan kamar tidur < 1\n",
    "MIN_BEDROOMS_NORMAL = 1\n",
    "low_outliers_df = df_platform_a[df_platform_a['bedrooms'] < MIN_BEDROOMS_NORMAL].copy()\n",
    "\n",
    "print(f\"\\nMenampilkan semua {len(low_outliers_df)} listing 'Outlier (Rendah)' di dalam Kota Bandung:\")\n",
    "\n",
    "# Menampilkan seluruh DataFrame (kita sudah mengatur opsi pd.display)\n",
    "print(low_outliers_df[[\n",
    "    'id', \n",
    "    'source', \n",
    "    'price', \n",
    "    'master_address',\n",
    "    'ADM4_EN', # Tampilkan kolom kecamatan baru kita!\n",
    "    'bedrooms', \n",
    "    'bathrooms', \n",
    "    'land_size_sqm', \n",
    "    'building_size_sqm'\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_outliers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0963dcb",
   "metadata": {},
   "source": [
    "**List of Anomalies (Post-Shapefile Filter)**  \n",
    "This list summarizes the remaining data quality issues *after* filtering for listings inside **Kota Bandung**.  \n",
    "\n",
    "---\n",
    "\n",
    "**1. Clear Misclassifications (Hotels & Land)**  \n",
    "The `property_type = 'Rumah'` classification is not perfect. Some listings are clearly not houses, often indicated by `bedrooms = 0`.  \n",
    "\n",
    "**Examples:**  \n",
    "- **Hotels:** Listing #5670 (`id = dijual-hotel-di-bandung...`) and #7201 (`id = hotel-bandung...`) are clearly hotels.  \n",
    "- **Land:** Listing #4631 (`id = tanah-mainroad-setiabudi...`) is clearly land.  \n",
    "\n",
    "---\n",
    "\n",
    "**2. Commercial Properties (Shophouses/Business Use)**  \n",
    "Many listings (also often with 0 bedrooms) have descriptions that strongly suggest they are for commercial, not residential, use.  \n",
    "\n",
    "**Examples:**  \n",
    "- Listing #1194: \"House Can Be Used For Cafe Business...\"  \n",
    "- Listing #3578: \"Residential House With Business Space...\"  \n",
    "- Listing #803: \"House On Mainroad...\" (usually commercial)  \n",
    "\n",
    "---\n",
    "\n",
    "**3. Logical Impossibilities (Size Typos)**  \n",
    "The data contains \"impossible\" minimum values that are typos.  \n",
    "*(Note: `building_size_sqm > land_size_sqm` is valid and indicates a multi-story home).*  \n",
    "\n",
    "**The Real Impossibility:**  \n",
    "- **Typos:** Listing #4563 shows `building_size_sqm = 1.00`, which is impossible.  \n",
    "- **General:** Any listing with `land_size_sqm` or `building_size_sqm` under a \"common sense\" threshold (e.g., < 20 sqm) is highly suspect.  \n",
    "\n",
    "---\n",
    "\n",
    "**4. \"0 Bedrooms AND 0 Bathrooms\" Issue**  \n",
    "A significant number of the `bedrooms = 0` listings also have `bathrooms = 0`.  \n",
    "\n",
    "**Note:** Listings with 0 bedrooms **and** 0 bathrooms are almost certainly not residential houses and are strong candidates for re-classification or removal.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d268c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Clean Shapefile Columns\n",
    "# ---\n",
    "\n",
    "print(\"Membersihkan kolom-kolom shapefile yang tidak perlu...\")\n",
    "\n",
    "# Daftar kolom yang tidak berguna dari output .describe() Anda\n",
    "columns_to_drop = [\n",
    "    'date', \n",
    "    'validOn', \n",
    "    'validTo', \n",
    "    'Shape_Leng', \n",
    "    'Shape_Area',\n",
    "    # Juga buang kolom PCODE (kode pos) dan nama Admin\n",
    "    # yang tidak kita perlukan, KECUALI ADM4_EN (kecamatan)\n",
    "    'ADM4_PCODE', 'ADM4_REF', 'ADM4ALT1EN', 'ADM4ALT2EN',\n",
    "    'ADM3_PCODE', 'ADM2_PCODE', 'ADM1_EN', 'ADM1_PCODE',\n",
    "    'ADM0_EN', 'ADM0_PCODE'\n",
    "]\n",
    "\n",
    "# Cek kolom yang ada sebelum mencoba membuangnya\n",
    "existing_cols_to_drop = [col for col in columns_to_drop if col in df_platform_a.columns]\n",
    "\n",
    "if existing_cols_to_drop:\n",
    "    print(f\"Kolom yang akan dibuang: {existing_cols_to_drop}\")\n",
    "    df_platform_a = df_platform_a.drop(columns=existing_cols_to_drop)\n",
    "    print(\"Pembersihan kolom selesai.\")\n",
    "else:\n",
    "    print(\"Kolom sudah dibersihkan pada langkah sebelumnya.\")\n",
    "\n",
    "print(\"Kolom 'ADM4_EN' (Kecamatan) dipertahankan untuk analisis fitur.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Diagnose \"0 Bed, 0 Bath\" Anomaly\n",
    "# ---\n",
    "print(\"Mengisolasi '0 Bedrooms AND 0 Bathrooms'...\")\n",
    "\n",
    "# Filter untuk 0 bedrooms DAN 0 bathrooms\n",
    "zero_bed_zero_bath_df = df_platform_a[\n",
    "    (df_platform_a['bedrooms'] == 0) & \n",
    "    (df_platform_a['bathrooms'] == 0)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nMenampilkan semua {len(zero_bed_zero_bath_df)} listings '0-Bed-0-Bath':\")\n",
    "\n",
    "# Menampilkan \"simple df\" yang Anda minta\n",
    "print(zero_bed_zero_bath_df[[\n",
    "    'id', \n",
    "    'source', \n",
    "    'price', \n",
    "    'master_address',\n",
    "    'ADM4_EN', # Kolom kecamatan yang kita simpan\n",
    "    'bedrooms', \n",
    "    'bathrooms', \n",
    "    'land_size_sqm', \n",
    "    'building_size_sqm',\n",
    "    'description' # Menambahkan deskripsi untuk petunjuk\n",
    "]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556bc10",
   "metadata": {},
   "source": [
    "21 \u00f7 6,009 \u00d7 100 \u2248 **0.35%** (# of listings with 0 bedrooms and bathrooms)\n",
    "For the house price prediction model, a \"House\" listing must have bedrooms and bathrooms.  \n",
    "Listings with `bedrooms = 0` **and** `bathrooms = 0` are, by definition, not residential houses.  \n",
    "They are pure noise and will damage the model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f145958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Drop \"0 Bed, 0 Bath\" Anomaly\n",
    "# ---\n",
    "print(\"Menghapus 21 listing '0-Bed-0-Bath'...\")\n",
    "\n",
    "rows_before = len(df_platform_a)\n",
    "print(f\"Listings 'Rumah' (sebelum filter): {rows_before:,}\")\n",
    "\n",
    "# 1. Cari index dari listing yang akan dibuang\n",
    "outlier_indices = df_platform_a[\n",
    "    (df_platform_a['bedrooms'] == 0) & \n",
    "    (df_platform_a['bathrooms'] == 0)\n",
    "].index\n",
    "\n",
    "print(f\"Menemukan {len(outlier_indices)} listing '0-Bed-0-Bath' untuk dihapus.\")\n",
    "\n",
    "# 2. Drop listing tersebut dari df_platform_a\n",
    "df_platform_a.drop(outlier_indices, inplace=True)\n",
    "\n",
    "rows_after = len(df_platform_a)\n",
    "print(f\"Listings 'Rumah' (setelah filter): {rows_after:,}\")\n",
    "print(f\"Total {rows_before - rows_after} listing telah dihapus.\")\n",
    "\n",
    "print(\"\\n--- Step Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c074b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Define our \"common sense\" thresholds ---\n",
    "# We are checking for any property with a size < 20 sqm\n",
    "MIN_SIZE_THRESHOLD = 20\n",
    "MAX_SIZE_THRESHOLD = 2000 # This is for the green visual box\n",
    "\n",
    "# --- 2. Create the new column for coloring (Your \"Red Dot\" request) ---\n",
    "print(f\"Analyzing all {len(df_platform_a)} listings for size typos...\")\n",
    "print(\"Creating 'size_category' for visualization...\")\n",
    "def categorize_size(row):\n",
    "    # Check for \"Impossible Typos\" first\n",
    "    # This checks if *either* land or building is impossibly small\n",
    "    if row['land_size_sqm'] < MIN_SIZE_THRESHOLD or row['building_size_sqm'] < MIN_SIZE_THRESHOLD:\n",
    "        return 'Impossible (Typo)'\n",
    "    else:\n",
    "        return 'Normal'\n",
    "\n",
    "# Apply this logic to create a new column\n",
    "# This code runs on ALL 5,988 rows in df_platform_a\n",
    "df_platform_a['size_category'] = df_platform_a.apply(categorize_size, axis=1)\n",
    "\n",
    "# This printout should now sum to 5,988\n",
    "print(df_platform_a['size_category'].value_counts())\n",
    "print(\"\\nDiagnosing size anomalies (land vs. building)...\")\n",
    "\n",
    "# --- 3. Create the Plot ---\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# This scatterplot will now plot all 5,988 points\n",
    "ax = sns.scatterplot(\n",
    "    data=df_platform_a, \n",
    "    x='land_size_sqm', \n",
    "    y='building_size_sqm', \n",
    "    alpha=0.6,\n",
    "    zorder=2,\n",
    "    hue='size_category', # <-- This colors the dots\n",
    "    palette={'Normal': 'blue', 'Impossible (Typo)': 'red'} # <-- This sets the colors\n",
    ")\n",
    "\n",
    "# Set plot limits\n",
    "x_max_lim = 5000\n",
    "y_max_lim = 5000\n",
    "ax.set_xlim(0, x_max_lim)\n",
    "ax.set_ylim(0, y_max_lim)\n",
    "\n",
    "# --- Add the Green Grid (Statistical Outlier Zone) ---\n",
    "highlight_color = 'lightgreen'\n",
    "highlight_alpha = 0.3\n",
    "\n",
    "# Add a vertical span for Land > 2000\n",
    "ax.axvspan(\n",
    "    MAX_SIZE_THRESHOLD, \n",
    "    x_max_lim, \n",
    "    color=highlight_color, \n",
    "    alpha=highlight_alpha, \n",
    "    zorder=-2\n",
    ")\n",
    "# Add a horizontal span for Building > 2000\n",
    "ax.axhspan(\n",
    "    MAX_SIZE_THRESHOLD, \n",
    "    y_max_lim, \n",
    "    color=highlight_color, \n",
    "    alpha=highlight_alpha, \n",
    "    zorder=-2\n",
    ")\n",
    "# --- End of Green Grid ---\n",
    "\n",
    "# Add the red dashed line for y=x\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "]\n",
    "ax.plot(lims, lims, 'r--', alpha=0.75, zorder=1, label='y=x (Land = Building)')\n",
    "\n",
    "ax.set_title('Diagnosis: All Size Outliers (Typos & Statistical)', fontsize=16)\n",
    "ax.set_xlabel('Land Size (sqm)', fontsize=12)\n",
    "ax.set_ylabel('Building Size (sqm)', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, zorder=-1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- 4. Inspect the \"Typos\" (The Red Dots) ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Inspecting 'Impossible (Typo)' listings (< {MIN_SIZE_THRESHOLD} sqm):\")\n",
    "\n",
    "# We filter the 5,988-row dataframe to find only the new 'Impossible (Typo)' ones\n",
    "impossible_mins_df = df_platform_a[df_platform_a['size_category'] == 'Impossible (Typo)']\n",
    "\n",
    "print(impossible_mins_df[\n",
    "    ['id', 'master_address', 'price', 'land_size_sqm', 'building_size_sqm', 'bedrooms']\n",
    "].sort_values(by='building_size_sqm'))\n",
    "\n",
    "\n",
    "# --- 5. Clean up the temporary column ---\n",
    "# We drop this column so it doesn't interfere with later steps\n",
    "df_platform_a = df_platform_a.drop(columns=['size_category'])\n",
    "print(\"\\nTemporary 'size_category' column removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0239d1ea",
   "metadata": {},
   "source": [
    "**Observation:**  \n",
    "- Vast majority of our Rumah data is concentrated in the 0\u20132000 sqm range.  The listings in the light-green grid (where `land_size_sqm > 2000` OR `building_size_sqm > 2000`) are the \"Statistical Impossibilities\" (outliers) we discussed. These are not houses; they are commercial properties, warehouses, or palaces that were misclassified.  \n",
    "- Some data are physically nonsensical. It represents a data entry error, not a real property. We can call them a **Logical Impossibility (Typos)**  \n",
    "This is data that has `land_size_sqm` or `building_size_sqm` that is at or near zero. (I use < 20 sqm as a \"common sense\" filter.)  \n",
    "A 1 sqm, 5 sqm, or even 15 sqm property is not a house. \n",
    "Listing #4563 (with `building_size_sqm = 1.00`) is the perfect example.  \n",
    "Such entries are invalid data points and must be removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2383777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define our min and max \"sensible\" thresholds ---\n",
    "MIN_SIZE_THRESHOLD = 20\n",
    "MAX_SIZE_THRESHOLD = 2000\n",
    "\n",
    "print(f\"--- Step: Filtering for Sensible Sizes ---\")\n",
    "initial_count = len(df_platform_a)\n",
    "print(f\"Listings (sebelum filter): {initial_count}\")\n",
    "\n",
    "# --- 2. Create the filter conditions ---\n",
    "# We want to KEEP rows that meet ALL of these conditions:\n",
    "condition_keep = (\n",
    "    (df_platform_a['land_size_sqm'] >= MIN_SIZE_THRESHOLD) &\n",
    "    (df_platform_a['building_size_sqm'] >= MIN_SIZE_THRESHOLD) &\n",
    "    (df_platform_a['land_size_sqm'] <= MAX_SIZE_THRESHOLD) &\n",
    "    (df_platform_a['building_size_sqm'] <= MAX_SIZE_THRESHOLD)\n",
    ")\n",
    "\n",
    "# --- 3. Apply the filter ---\n",
    "# We create a new dataframe 'df_platform_a_cleaned' by selecting only the rows\n",
    "# that match our 'condition_keep'.\n",
    "df_platform_a_cleaned = df_platform_a[condition_keep].copy()\n",
    "\n",
    "# --- 4. Report and Finalize ---\n",
    "final_count = len(df_platform_a_cleaned)\n",
    "removed_count = initial_count - final_count\n",
    "\n",
    "print(f\"Listings (setelah filter): {final_count}\")\n",
    "print(f\"Total {removed_count} listings (typos & outliers) telah dihapus.\")\n",
    "\n",
    "# --- 5. Overwrite the main dataframe ---\n",
    "# Our main dataframe 'df_platform_a' is now the cleaned version\n",
    "df_platform_a = df_platform_a_cleaned\n",
    "\n",
    "print(\"\\nDataframe 'df_platform_a' telah diperbarui.\")\n",
    "print(\"--- Step Selesai ---\")\n",
    "\n",
    "# Optional: You can uncomment this to see the new shape\n",
    "# print(df_platform_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step: Isolating 0-Bedroom Listings ---\n",
    "print(f\"Analyzing {len(df_platform_a)} listings (after size cleaning)...\")\n",
    "\n",
    "# --- 1. Define the minimum threshold ---\n",
    "MIN_BEDROOMS_NORMAL = 1\n",
    "\n",
    "# --- 2. Filter 'df_platform_a' (5,954 listings) ---\n",
    "# Find listings with bedrooms < 1 (i.e., 0 bedrooms)\n",
    "low_outliers_df = df_platform_a[df_platform_a['bedrooms'] < MIN_BEDROOMS_NORMAL].copy()\n",
    "\n",
    "print(f\"\\nFound {len(low_outliers_df)} '0-Bedroom' (Outlier (Low)) listings.\")\n",
    "\n",
    "# --- 3. Display the details of these listings ---\n",
    "print(\"Displaying details for these listings:\")\n",
    "\n",
    "# This print statement is corrected from your snippet\n",
    "print(low_outliers_df[[\n",
    "    'id', \n",
    "    'source', \n",
    "    'price', \n",
    "    'master_address',\n",
    "    'ADM4_EN', \n",
    "    'bedrooms', \n",
    "    'bathrooms', \n",
    "    'land_size_sqm', \n",
    "    'building_size_sqm'  # <-- Fixed the extra quote here\n",
    "]])\n",
    "\n",
    "print(\"\\n'low_outliers_df' is ready for inspection.\")\n",
    "print(\"--- Step Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb029e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_outliers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4384e",
   "metadata": {},
   "source": [
    "**What's No Longer an Anomaly**  \n",
    "\n",
    "**Size Typos: FIXED**  \n",
    "All the `land_size_sqm` and `building_size_sqm` values in your sample (60, 198, 824, 89, etc.) are valid and fall within our sensible 20\u20132000 sqm range.  \n",
    "\n",
    "**0-Bed/0-Bath: FIXED**  \n",
    "All the listings in your sample have at least one bathroom.  \n",
    "\n",
    "**Location: FIXED**  \n",
    "We can see ADM4_EN (kecamatan) names like Mekarjaya, Sukamaju, and Dago, confirming they are all inside Bandung.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f638c",
   "metadata": {},
   "source": [
    "**Remaining Anomalies**  \n",
    "\n",
    "We are left with listings that have 0 bedrooms but 1, 2, 3, or even 5 bathrooms.  \n",
    "A residential house with 5 bathrooms and 0 bedrooms is a logical impossibility.  \n",
    "\n",
    "The most likely explanation is that these are misclassified properties such as:  \n",
    "- Ruko (Shophouse)  \n",
    "- Kantor (Office)  \n",
    "- Restoran (Restaurant)  \n",
    "- Gudang (Warehouse)  \n",
    "\n",
    "---\n",
    "\n",
    "**Evidence**  \n",
    "\n",
    "**Commercial Use**  \n",
    "- Index 4370 (6.5 Billion IDR): The description explicitly says *\"Rumah/ Ruang Usaha Mainroad Moch Toha\"* (House / Commercial Space).  \n",
    "- Index 803 (34.6 Billion IDR): The price is enormous for a 0-bed, 1-bath property. The description *\"Rumah Mainroad Dago\"* confirms it is a commercial-value property on a main road.  \n",
    "\n",
    "**Logical Impossibility (likely commercial or error)**  \n",
    "- Index 2843 (5 Billion IDR): Has 0 bedrooms and 5 bathrooms.  \n",
    "- Index 4108 (1.4 Billion IDR): Also has 0 bedrooms and 5 bathrooms.  \n",
    "- Index 6356 (2.75 Billion IDR): Also has 0 bedrooms and 5 bathrooms.  \n",
    "- Index 570 (2.6 Billion IDR): Has 0 bedrooms and 4 bathrooms.  \n",
    "\n",
    "**Likely Data Error**  \n",
    "- Index 301 (690 Million IDR): Has 0 bedrooms and 3 bathrooms. At this price, it is most likely the agent simply forgot to enter the bedroom count.  \n",
    "\n",
    "11 out of 5,954 is $0.1847\\%$.This is a very small fraction (less than one-fifth of one percent) of the total dataset. I will remove them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of 0-Bedroom Listings\n",
    "MIN_BEDROOMS_NORMAL = 1\n",
    "initial_count = len(df_platform_a)\n",
    "\n",
    "print(f\"Listings (sebelum filter): {initial_count}\")\n",
    "\n",
    "# --- 2. Create the filter condition ---\n",
    "# We want to KEEP rows where bedrooms are 1 or more\n",
    "condition_keep = (df_platform_a['bedrooms'] >= MIN_BEDROOMS_NORMAL)\n",
    "\n",
    "# --- 3. Apply the filter ---\n",
    "# Overwrite 'df_platform_a' with the filtered version\n",
    "df_platform_a = df_platform_a[condition_keep].copy()\n",
    "\n",
    "# --- 4. Report and Finalize ---\n",
    "final_count = len(df_platform_a)\n",
    "removed_count = initial_count - final_count\n",
    "\n",
    "print(f\"Listings (setelah filter): {final_count}\")\n",
    "print(f\"Total {removed_count} listing '0-Bedroom' telah dihapus.\")\n",
    "print(\"\\nDataframe 'df_platform_a' telah diperbarui.\")\n",
    "print(\"--- Step Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platform_a.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b899df",
   "metadata": {},
   "source": [
    "**Current Anomalies**\n",
    "\n",
    "**1. Extreme Price Outliers**  \n",
    "This is the most obvious issue.  \n",
    "\n",
    "- 75% (Upper Quartile): 4.7 Billion IDR  \n",
    "- Max: 950 Billion IDR  \n",
    "\n",
    "A price of 950 Billion is not a house; it is a massive development project, a huge typo (extra zeros), or a commercial property. It will break any statistical model.  \n",
    "\n",
    "---\n",
    "\n",
    "**2. Extreme High Bedrooms/Bathrooms**  \n",
    "These are not standard houses and are likely misclassified.  \n",
    "\n",
    "- **Bedrooms:** The 75th percentile is 5, but the maximum is 60. A 60-bedroom \"house\" is a Kost (boarding house) or a small hotel.  \n",
    "- **Bathrooms:** The 75th percentile is 3, but the maximum is 57. This is also not a residential home.  \n",
    "\n",
    "---\n",
    "\n",
    "**3. Zero Bathrooms**  \n",
    "- Bathrooms: The minimum is 0.00.  \n",
    "- We previously removed listings with 0 beds **and** 0 baths.  \n",
    "- Now we have listings with 1+ beds but 0 baths.  \n",
    "\n",
    "This is a strong indicator of a data entry error and is just as problematic as the 0-bedroom listings.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Define our thresholds ---\n",
    "MAX_ROOM_THRESHOLD = 20 \n",
    "\n",
    "# --- 2. Create the new column for coloring ---\n",
    "print(f\"Analyzing all {len(df_platform_a)} listings for room anomalies...\")\n",
    "print(\"Creating 'room_category' for visualization...\")\n",
    "\n",
    "def categorize_rooms(row):\n",
    "    # Priority 1: Check for Typos (0 Bathrooms)\n",
    "    if row['bathrooms'] < 1:\n",
    "        return 'Impossible (Typo)'\n",
    "    # Priority 2: Check for High Outliers (> 20 Rooms)\n",
    "    elif row['bedrooms'] > MAX_ROOM_THRESHOLD or row['bathrooms'] > MAX_ROOM_THRESHOLD:\n",
    "        return 'Outlier (High)'\n",
    "    # Priority 3: Normal\n",
    "    else:\n",
    "        return 'Normal'\n",
    "\n",
    "# Apply this logic\n",
    "df_platform_a['room_category'] = df_platform_a.apply(categorize_rooms, axis=1)\n",
    "\n",
    "print(df_platform_a['room_category'].value_counts())\n",
    "\n",
    "# --- 3. Create Jittered Data for Plotting ---\n",
    "x_jittered = df_platform_a['bedrooms'] + np.random.normal(0, 0.25, size=len(df_platform_a))\n",
    "y_jittered = df_platform_a['bathrooms'] + np.random.normal(0, 0.25, size=len(df_platform_a))\n",
    "\n",
    "# --- 4. Create the Plot ---\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = sns.scatterplot(\n",
    "    x=x_jittered, \n",
    "    y=y_jittered, \n",
    "    alpha=0.6, \n",
    "    zorder=2,\n",
    "    hue=df_platform_a['room_category'], \n",
    "    # Define the exact colors you asked for\n",
    "    palette={\n",
    "        'Normal': 'orange', \n",
    "        'Impossible (Typo)': 'red', \n",
    "        'Outlier (High)': 'black'\n",
    "    } \n",
    ")\n",
    "\n",
    "# Set plot limits\n",
    "max_lim = 65 \n",
    "ax.set_xlim(-1, max_lim)\n",
    "ax.set_ylim(-1, max_lim)\n",
    "\n",
    "# --- Add the Blue Grid (Statistical Outlier Zone) ---\n",
    "highlight_color = 'lightblue'\n",
    "highlight_alpha = 0.3\n",
    "\n",
    "# Vertical span (Bedrooms > 20)\n",
    "ax.axvspan(\n",
    "    MAX_ROOM_THRESHOLD, \n",
    "    max_lim, \n",
    "    color=highlight_color, \n",
    "    alpha=highlight_alpha, \n",
    "    zorder=-2\n",
    ")\n",
    "# Horizontal span (Bathrooms > 20)\n",
    "ax.axhspan(\n",
    "    MAX_ROOM_THRESHOLD, \n",
    "    max_lim, \n",
    "    color=highlight_color, \n",
    "    alpha=highlight_alpha, \n",
    "    zorder=-2\n",
    ")\n",
    "\n",
    "# Add the red dashed line for y=x\n",
    "lims = [0, max_lim]\n",
    "ax.plot(lims, lims, 'r--', alpha=0.75, zorder=1, label='y=x (Bedrooms = Bathrooms)')\n",
    "\n",
    "ax.set_title('Diagnosis: Bedrooms vs Bathrooms (Black=High Outlier, Red=Typo)', fontsize=16)\n",
    "ax.set_xlabel('Bedrooms (Jittered)', fontsize=12)\n",
    "ax.set_ylabel('Bathrooms (Jittered)', fontsize=12)\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, zorder=-1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- 5. Inspect the \"Typos\" (The Red Dots) ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Inspecting 'Impossible (Typo)' listings (0 Bathrooms):\")\n",
    "\n",
    "# Filter for the red dots\n",
    "impossible_rooms_df = df_platform_a[df_platform_a['room_category'] == 'Impossible (Typo)']\n",
    "\n",
    "if len(impossible_rooms_df) > 0:\n",
    "    print(impossible_rooms_df[\n",
    "        ['id', 'price', 'bedrooms', 'bathrooms', 'land_size_sqm', 'building_size_sqm']\n",
    "    ].sort_values(by='bedrooms'))\n",
    "else:\n",
    "    print(\"No 0-bathroom listings found!\")\n",
    "\n",
    "# Clean up\n",
    "df_platform_a = df_platform_a.drop(columns=['room_category'])\n",
    "print(\"\\nTemporary 'room_category' column removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3dcf70",
   "metadata": {},
   "source": [
    "**Graph Analysis (The \"Map\")**  \n",
    "\n",
    "**Red Dots (0-Bathroom Error):**  \n",
    "A row of red dots along y=0 confirms listings with valid bedroom counts (2, 3, 4, even 19) but zero bathrooms.  \n",
    "\n",
    "9 Typos (0 Bathrooms)\n",
    "\n",
    "**Black Dots (High Outliers):**  \n",
    "- Properties with more than 20 bedrooms or bathrooms.  \n",
    "- One extreme outlier has about 60 bedrooms.  \n",
    "- Another cluster has 20\u201340 bedrooms.  \n",
    "\n",
    "These are clearly non-residential (Kost, Hotels) and should be removed.  50 High Outliers (Commercial/Kost)\n",
    "We are targeting exactly 59 listings for removal.\n",
    "\n",
    "**Big Picture:**  \n",
    "Most of the data (the orange cloud) looks normal. It clusters in the bottom-left, showing that most houses in Bandung have 1\u20135 bedrooms and 1\u20134 bathrooms. This is the expected pattern.  \n",
    "5943 - 59 = 5887 remaining listings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075492b1",
   "metadata": {},
   "source": [
    "In addition, i will remove 1 particular listing. It's a \"Normal\" house by our current definition (not 0 bathrooms, not >20 rooms), but it visually sticks out in an unexpected way. It looks like it has around 1-2 bedrooms but about 21 bathrooms. This is a very clear anomaly for a residential home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Consolidated Fix: Cleaning Room Anomalies ---\n",
    "print(\"--- Step: Finalizing Room Anomalies (Typos & High Outliers) ---\")\n",
    "\n",
    "# 1. Capture the starting state\n",
    "initial_count = len(df_platform_a)\n",
    "print(f\"Listings start: {initial_count}\")\n",
    "\n",
    "# 2. Define Thresholds\n",
    "MIN_BATHROOMS = 1        # Must have at least 1 bathroom\n",
    "MAX_ROOM_THRESHOLD = 20  # Max 20 beds or baths\n",
    "\n",
    "# 3. Apply the Filter\n",
    "# We KEEP rows that meet ALL these criteria:\n",
    "condition_keep = (\n",
    "    (df_platform_a['bathrooms'] >= MIN_BATHROOMS) &\n",
    "    (df_platform_a['bedrooms'] <= MAX_ROOM_THRESHOLD) &\n",
    "    (df_platform_a['bathrooms'] <= MAX_ROOM_THRESHOLD)\n",
    ")\n",
    "\n",
    "# 4. Execute the Drop\n",
    "df_platform_a_cleaned = df_platform_a[condition_keep].copy()\n",
    "\n",
    "# 5. Calculate what was removed\n",
    "final_count = len(df_platform_a_cleaned)\n",
    "removed_count = initial_count - final_count\n",
    "\n",
    "print(f\"Listings end  : {final_count}\")\n",
    "print(f\"Total removed : {removed_count}\")\n",
    "\n",
    "# 6. Verify ID 1788 (The 21-bathroom house)\n",
    "# We check if it exists in the CLEANED data. It should be empty.\n",
    "check_1788 = df_platform_a_cleaned[df_platform_a_cleaned['bathrooms'] == 21]\n",
    "if check_1788.empty:\n",
    "    print(\"\\nVerification: Listing with 21 bathrooms (ID 1788) was successfully removed by the threshold filter.\")\n",
    "else:\n",
    "    print(\"\\nWarning: ID 1788 still exists!\")\n",
    "\n",
    "# 7. Overwrite the main dataframe\n",
    "df_platform_a = df_platform_a_cleaned\n",
    "print(\"--- Step Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15055ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platform_a.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f015eb",
   "metadata": {},
   "source": [
    "**Remaining Anomalies Are Entirely in the Price**  \n",
    "\n",
    "**1. The \"Impossible\" Maximum (950 Billion IDR)**  \n",
    "- **Stat:** Max Price = 950,000,000,000  \n",
    "- **Logic:** A price of 950 Billion is ~200 times higher than the \"expensive\" houses in the dataset (75th percentile is 4.6 Billion).  \n",
    "- **Diagnosis:** This is likely a massive development project (selling 100 units at once), a large commercial complex, or a typo (extra zeros). It distorts the Mean and Standard Deviation.  \n",
    "\n",
    "---\n",
    "\n",
    "**2. The \"Rental\" Minimum (45 Million IDR)**  \n",
    "- **Stat:** Min Price = 45,000,000  \n",
    "- **Logic:** You cannot buy a house in Bandung for 45 Million. Even subsidized housing (*Rumah Subsidi*) is usually >150 Million.  \n",
    "- **Diagnosis:** This is almost certainly a rental listing (per year) misclassified as a sale, or possibly just a small plot of land.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43de854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Step: Price Diagnosis (Red, Yellow, Green) ---\n",
    "print(f\"Applying Price Logic to {len(df_platform_a)} listings...\")\n",
    "\n",
    "# 1. Define Thresholds\n",
    "MIN_PRICE_THRESHOLD = 150_000_000       # 150 Juta (Likely Typos/Rentals)\n",
    "MAX_PRICE_THRESHOLD = 100_000_000_000   # 100 Milyar (Luxury/Commercial)\n",
    "\n",
    "# 2. Create Categories for Coloring\n",
    "def categorize_price(price):\n",
    "    if price < MIN_PRICE_THRESHOLD:\n",
    "        return 'Impossible (Low)'\n",
    "    elif price > MAX_PRICE_THRESHOLD:\n",
    "        return 'Outlier (High)'\n",
    "    else:\n",
    "        return 'Normal'\n",
    "\n",
    "df_platform_a['price_category'] = df_platform_a['price'].apply(categorize_price)\n",
    "\n",
    "print(\"\\nCounts by Category:\")\n",
    "print(df_platform_a['price_category'].value_counts())\n",
    "\n",
    "# 3. Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Convert Price to Billions for plotting\n",
    "df_platform_a['price_milyar'] = df_platform_a['price'] / 1_000_000_000\n",
    "\n",
    "ax = sns.scatterplot(\n",
    "    data=df_platform_a,\n",
    "    x='land_size_sqm',\n",
    "    y='price_milyar',\n",
    "    hue='price_category',\n",
    "    palette={\n",
    "        'Normal': 'green', \n",
    "        'Outlier (High)': 'red', \n",
    "        'Impossible (Low)': 'yellow'\n",
    "    },\n",
    "    alpha=0.7,\n",
    "    s=60,\n",
    "    edgecolor='black', # Adds a black outline so Yellow dots are visible\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "ax.set_title('Price Diagnosis: Red (>100B), Yellow (<150M), Green (Normal)', fontsize=16)\n",
    "ax.set_xlabel('Land Size (sqm)', fontsize=12)\n",
    "ax.set_ylabel('Price (Billions IDR)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Force Y-axis to plain numbers\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Inspecting the \"Yellow\" (Low) Listings\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INSPECTION: Impossible (Low) Listings (< 150 Juta)\")\n",
    "low_outliers = df_platform_a[df_platform_a['price_category'] == 'Impossible (Low)']\n",
    "\n",
    "if not low_outliers.empty:\n",
    "    print(low_outliers[['id', 'price', 'land_size_sqm', 'master_address']].sort_values(by='price'))\n",
    "else:\n",
    "    print(\"No listings found below 150 Million IDR.\")\n",
    "\n",
    "# Clean up\n",
    "df_platform_a = df_platform_a.drop(columns=['price_milyar', 'price_category'])\n",
    "print(\"\\n--- Step Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Step: Mapping the \"Normal Zone\" (Zoomed In) ---\n",
    "print(f\"Zooming in on the market (filtering out > 100 Billion temporarily)...\")\n",
    "\n",
    "# 1. Define Thresholds\n",
    "MAX_PRICE_VIEW = 100_000_000_000  # 100 Milyar (The Ceiling for this view)\n",
    "MIN_PRICE_TYPO = 150_000_000      # 150 Juta (The Floor for Typos)\n",
    "\n",
    "# 2. Create a temporary subset for visualization ONLY\n",
    "#    We keep everything <= 100 Billion\n",
    "df_zoom = df_platform_a[df_platform_a['price'] <= MAX_PRICE_VIEW].copy()\n",
    "\n",
    "# 3. Define categories for this zoomed view\n",
    "#    Since we removed the 'Red' (>100B), we only have 'Normal' and 'Impossible (Low)'\n",
    "def categorize_zoomed(price):\n",
    "    if price < MIN_PRICE_TYPO:\n",
    "        return 'Impossible (Low)'\n",
    "    else:\n",
    "        return 'Normal'\n",
    "\n",
    "df_zoom['price_category'] = df_zoom['price'].apply(categorize_zoomed)\n",
    "\n",
    "print(f\"Showing {len(df_zoom)} listings (Hidden {len(df_platform_a) - len(df_zoom)} extreme outliers).\")\n",
    "\n",
    "# 4. Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Convert to Billions for Y-axis\n",
    "df_zoom['price_milyar'] = df_zoom['price'] / 1_000_000_000\n",
    "\n",
    "ax = sns.scatterplot(\n",
    "    data=df_zoom,\n",
    "    x='land_size_sqm',\n",
    "    y='price_milyar',\n",
    "    hue='price_category',\n",
    "    palette={\n",
    "        'Normal': 'green', \n",
    "        'Impossible (Low)': 'yellow'\n",
    "    },\n",
    "    alpha=0.5, # Lower alpha to see density in the \"Normal\" cloud\n",
    "    s=50,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.3\n",
    ")\n",
    "\n",
    "ax.set_title(f'The \"Real\" Market Shape (Zoomed: Price <= 100 Billion)', fontsize=16)\n",
    "ax.set_xlabel('Land Size (sqm)', fontsize=12)\n",
    "ax.set_ylabel('Price (Billions IDR)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Force Y-axis to plain numbers\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"--- Zoomed Map Generated ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step: Removing Price Anomalies (Inplace) ---\n",
    "print(f\"--- Step: Cleaning Price Outliers & Typos ---\")\n",
    "\n",
    "# 1. Define the Thresholds (as agreed)\n",
    "MIN_PRICE_TYPO = 150_000_000        # < 150 Juta (Remove)\n",
    "MAX_PRICE_OUTLIER = 100_000_000_000 # > 100 Milyar (Remove)\n",
    "\n",
    "initial_count = len(df_platform_a)\n",
    "print(f\"Listings (sebelum filter): {initial_count}\")\n",
    "\n",
    "# 2. Create the filter condition\n",
    "# We KEEP rows that are within the \"Normal\" range\n",
    "condition_keep = (\n",
    "    (df_platform_a['price'] >= MIN_PRICE_TYPO) & \n",
    "    (df_platform_a['price'] <= MAX_PRICE_OUTLIER)\n",
    ")\n",
    "\n",
    "# 3. Apply the filter (Overwrite df_platform_a)\n",
    "df_platform_a = df_platform_a[condition_keep].copy()\n",
    "\n",
    "# 4. Report results\n",
    "final_count = len(df_platform_a)\n",
    "removed_count = initial_count - final_count\n",
    "\n",
    "print(f\"Listings (setelah filter): {final_count}\")\n",
    "print(f\"Total {removed_count} listings removed.\")\n",
    "print(f\"   (Removed: Prices < {MIN_PRICE_TYPO:,.0f} or > {MAX_PRICE_OUTLIER:,.0f})\")\n",
    "print(\"\\nDataframe 'df_platform_a' updated.\")\n",
    "print(\"--- Step Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725dea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platform_a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21cf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"--- Plotting Final Verification Map (Price Heatmap) ---\")\n",
    "\n",
    "# 1. Load the Shapefile\n",
    "shapefile_path = r\"..\\data\\raw\\idn_admbnda_adm4_ID3_bps_20200401.shp\"\n",
    "print(\"Loading shapefile...\")\n",
    "\n",
    "try:\n",
    "    gdf_adm = gpd.read_file(shapefile_path)\n",
    "    \n",
    "    # Filter for Kota Bandung\n",
    "    bandung_gdf = gdf_adm[gdf_adm['ADM2_EN'] == 'Kota Bandung'].copy()\n",
    "    bandung_gdf = bandung_gdf.to_crs(\"EPSG:4326\") # Ensure Standard Lat/Lon\n",
    "    print(\"Bandung map boundaries loaded.\")\n",
    "\n",
    "    # 2. Convert clean 'df_platform_a' to GeoDataFrame\n",
    "    gdf_listings_filtered = gpd.GeoDataFrame(\n",
    "        df_platform_a, \n",
    "        geometry=gpd.points_from_xy(df_platform_a.longitude, df_platform_a.latitude), \n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    print(f\"Loaded {len(gdf_listings_filtered)} listings for plotting.\")\n",
    "\n",
    "    # 3. Plot the Map\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # A. Plot Base Map (Grey Background)\n",
    "    bandung_gdf.plot(\n",
    "        ax=ax, \n",
    "        edgecolor='black', \n",
    "        facecolor='#dddddd', \n",
    "        label='Kota Bandung Boundary',\n",
    "        zorder=1\n",
    "    )\n",
    "    \n",
    "    # B. Plot Listings (Colored by Price)\n",
    "    gdf_listings_filtered.plot(\n",
    "        ax=ax, \n",
    "        column='price',        # Use price for color\n",
    "        cmap='viridis_r',      # Reverse Viridis (Purple=High, Yellow=Low usually, or vice versa depending on version)\n",
    "        markersize=15,         # Size of dots\n",
    "        alpha=0.7,             # Transparency\n",
    "        legend=True,\n",
    "        legend_kwds={\n",
    "            'label': \"Price (IDR)\", \n",
    "            'shrink': 0.6,\n",
    "            'format': \"%.0e\"   # Scientific notation for cleaner legend\n",
    "        },\n",
    "        vmax=15_000_000_000,   # CAP visual scale at 15 Billion so normal houses show variation\n",
    "        zorder=2\n",
    "    )\n",
    "    \n",
    "    # C. Set Verification Limits (Your specific coordinates)\n",
    "    ax.set_xlim(107.55, 107.74)\n",
    "    ax.set_ylim(-6.98, -6.83)\n",
    "    \n",
    "    # D. Formatting\n",
    "    ax.set_title(f'Verification: {len(gdf_listings_filtered)} Clean Listings (Colored by Price)', fontsize=16)\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.savefig('kota_bandung_clean_price_map.png')\n",
    "    print(\"Map generation complete. Saved as 'kota_bandung_clean_price_map.png'\")\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d58deb",
   "metadata": {},
   "source": [
    "We are done with Data Cleaning. We are ready for Feature Engineering (e.g., Price per Square Meter) or Exploratory Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- Final Step: Saving to 'data/processed' ---\n",
    "\n",
    "# 1. Define the directory and filename\n",
    "save_dir = r\"..\\data\\processed\"\n",
    "filename = \"df_platform_a_bandung_cleaned.csv\"\n",
    "\n",
    "# 2. Create the full path\n",
    "full_path = os.path.join(save_dir, filename)\n",
    "\n",
    "print(f\"Saving {len(df_platform_a)} cleaned listings to:\\n{full_path}...\")\n",
    "\n",
    "# 3. Save (Index=False)\n",
    "# Ensure the directory exists, just in case\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "df_platform_a.to_csv(full_path, index=False)\n",
    "\n",
    "print(\"\u2705 Save Complete.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Final Data Shape: {df_platform_a.shape}\")\n",
    "print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bandung-housing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}